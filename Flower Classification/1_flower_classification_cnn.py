# -*- coding: utf-8 -*-
"""1. Flower Classification_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12RDqSMmPMX8sbkakD3fMcS31a4c1hwGA

## **Probelm Statement**
The objective of this case study is to predict the class of flower using computer vision techniques such as CNN and RESNET.

## **Importing necessary libraries**
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
import PIL #PIL stands for Python Imaging Library. It is used to process image in different format using Python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

"""## **Downloading Dataset**
I have used tf.keras.utils.get_file to download the data in keras cache directory using pathlib module.
"""

import pathlib
dataset_url = "https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"
data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)
data_dir = pathlib.Path(data_dir)

"""## **Exploring Dataset**
Checking how many total images are there and viewing the images of some flowers and using PIL library to process the image and defining the batch_size, height and width of the image.
"""

# Getting image count
image_count = len(list(data_dir.glob('*/*.jpg')))
print(image_count)

# Getting the first image
roses = list(data_dir.glob('roses/*'))
PIL.Image.open(str(roses[0]))

PIL.Image.open(str(roses[1]))

# Checking for Tulips
tulips = list(data_dir.glob('tulips/*'))
PIL.Image.open(str(tulips[0]))

# Defining batch_size, height and width of image
batch_size = 32
img_height = 180
img_width = 180

"""## **Creating training and validation subset**
Spliting the dataset into training and validation with train and validation split of 80:20
"""

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset='training',
    seed=123,
    image_size=(img_height,img_width),
    batch_size=batch_size
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset='validation',
    seed=123,
    image_size=(img_height,img_width),
    batch_size=batch_size
)

"""**There are 5 classes in the dataset such as roses, daisy, dandelion, sunflowers and tulips.**"""

class_names = train_ds.class_names
print(class_names)

"""## **Visualizing the data**"""

# Set up the figure size
plt.figure(figsize=(10, 10))

# Loop through the first batch of images and labels
for images, labels in train_ds.take(1):
    # Loop through the first 9 images
    for i in range(9):
        # Create a subplot for each image
        ax = plt.subplot(3, 3, i + 1)

        # Display the image
        plt.imshow(images[i].numpy().astype('uint8'))

        # Set the title of the image
        plt.title(class_names[labels[i]])

        # Turn off the axis
        plt.axis("off")

"""## **Checking size of image_batch and labels_batch**
The image batch is the tensor of the shape (32,180,180,3). The batch 32 images of shape 180x180x3. The last dimension shows the color channels RGB. The label_batch is a tensor of the shape (32), corresponding labels to the 32 images.
"""

# Loop through the batches in train_ds
for batch_num, (images, labels) in enumerate(train_ds):
    # Print the shape of the current batch of images and labels
    print(f"Batch {batch_num + 1}:")
    print(f"Images shape: {images.shape}")
    print(f"Labels shape: {labels.shape}")

    # Stop the loop after processing the first batch
    break

"""## **Configuring datasets for performance**
dataset.cache() keeps the images in memory after they are loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training the model
"""

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)
val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)

"""## **Standardization of the data**
Standardize values to be in the [0,1] range by using a Rescaling layer. The RGB channel values are in the [0,255] range. This is not ideal for a neural network; in general you should seek to make your input values to be small standardize values to be small standardize values to be in the [0,1] range by using a Rescaling layer.
"""

# Define a normalization layer to rescale pixel values
normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)

# Apply normalization to the training dataset
normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))

# Get a batch of normalized images and labels
image_batch, labels_batch = next(iter(normalized_ds))

# Extract the first image from the batch
first_image = image_batch[0]

# Print the minimum and maximum pixel values of the first image
print(np.min(first_image), np.max(first_image))

"""## **Building CNN Model**
The model has three convolution blocks with a max pool layer in each of them. There's a fully connected layer with 128 units on top of it that is activated by a relu activation function and then compiling the model and checking for model summary which give the number of trainable parameters and non-trainable parameters.
"""

num_classes = 5
model = Sequential([
    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
    layers.Conv2D(16,3,padding='same',activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(32,3,padding='same',activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(64,3,padding='same',activation='relu'),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128,activation='relu'),
    layers.Dense(num_classes)
])

# Compile the model:
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.summary()

"""## **Training the model using epochs**
I am using 10 epochs to train the model and for each epoch will check the model's training and validation accuracy with the corresponding loss.
"""

epochs = 10
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=epochs
)

"""## **Plotting graph for comparision of training and validation accuracy**"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

epochs_range = range(epochs)

plt.figure(figsize=(8,8))
plt.subplot(1,2,1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Valiation Accuracy')

"""## **Conclusion**
Training accuracy is going around 98% where as validation accuracy is not even touching 70%. This shows that CNN model is overfitting and not performing well when building a complex model. Will try to solve the problem of overfiting using RESNET.
"""





